{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Lambeth DataNet (LDN)</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "London perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser();\n",
    "config.read('config.properties');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEC distributions\n",
    "ldn_sec_low_proportion_100, ldn_sec_mid_proportion_100, ldn_sec_high_proportion_100 = 0, 0, 0;\n",
    "# Ethnicity distributions\n",
    "ldn_ethnicity_white_british_proportion_100, ldn_ethnicity_minority_proportion_100 = 0, 0;\n",
    "# SEC + Asthma distributions\n",
    "ldn_sec_low_asthma_proportion_100, ldn_sec_mid_asthma_proportion_100, ldn_sec_high_asthma_proportion_100, ldn_sec_low_non_asthma_proportion_100, ldn_sec_mid_non_asthma_proportion_100, ldn_sec_high_non_asthma_proportion_100 = 0, 0, 0, 0, 0, 0;\n",
    "# Ethnicity + Asthma distributions\n",
    "ldn_ethnicity_white_asthma_proportion_100, ldn_ethnicity_minority_asthma_proportion_100, ldn_ethnicity_white_non_asthma_proportion_100, ldn_ethnicity_minority_non_asthma_proportion_100, = 0, 0, 0, 0;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66557\n"
     ]
    }
   ],
   "source": [
    "# load patient data\n",
    "individuals = {};\n",
    "class Individual:\n",
    "    def __init__(self, id, age, sex, lsoa, in_lambeth, ethnicity_a, ethnicity_b):\n",
    "        self.__id = id;\n",
    "        self.__age = age;\n",
    "        self.__sex = sex;\n",
    "        self.__lsoa = lsoa;\n",
    "        self.__in_lambeth = in_lambeth;\n",
    "        self.__ethnicity_a = ethnicity_a;\n",
    "        self.__ethnicity_b = ethnicity_b;\n",
    "\n",
    "    def get_id(self): return self.__id;\n",
    "    def get_age(self): return self.__age;\n",
    "    def get_sex(self): return self.__sex;\n",
    "    def get_lsoa(self): return self.__lsoa;\n",
    "    def get_in_lambeth(self): return self.__in_lambeth;\n",
    "    def get_ethnicity_a(self): return self.__ethnicity_a;\n",
    "    def get_ethnicity_b(self): return self.__ethnicity_b;\n",
    "\n",
    "\n",
    "with open(config.get('data', 'ldn.path_cohort')) as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        # ~MDC 14/03 there's probably already a package for this\n",
    "        individuals[row['patient_id']] = Individual(row['patient_id'], int(row['ageatrefdate']), ('M' if int(row['sex']) == 1 else 'F'), row['lsoa2011'], int(row['in_lambeth']), int(row['eth_5']) if row['eth_5'] else -1, int(row['eth_18']) if row['eth_18'] else -1);\n",
    "\n",
    "# print number of individuals (for interest)\n",
    "print(len(individuals));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>SEC</h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1026\n"
     ]
    }
   ],
   "source": [
    "# print number of lsoas (just for interest)\n",
    "with open(config.get('data', 'ldn.path_iod')) as f:\n",
    "    reader = csv.DictReader(f);\n",
    "    print(len(list(reader)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match each lsoa to an sec group (low, mid or high) based upon 1-10 ranking on employment iod\n",
    "lsoa_to_sec = {};\n",
    "with open(config.get('data', 'ldn.path_iod')) as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        if(not row['iod_employ_decile']): continue;\n",
    "        iod_employ_decile = int(row['iod_employ_decile']);\n",
    "        if(iod_employ_decile>=1 and iod_employ_decile<=3):\n",
    "            lsoa_to_sec[row['lsoa2011']] = 'low';\n",
    "        elif(iod_employ_decile>=4 and iod_employ_decile<=7):\n",
    "            lsoa_to_sec[row['lsoa2011']] = 'mid';\n",
    "        elif(iod_employ_decile>=8 and iod_employ_decile<=10):\n",
    "            lsoa_to_sec[row['lsoa2011']] = 'high';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mid': 508, 'low': 288, 'high': 198}\n"
     ]
    }
   ],
   "source": [
    "# count number of lsoas in each group (just for interest)\n",
    "sec_grouped = {};\n",
    "for entry in lsoa_to_sec.items(): \n",
    "    sec_grouped.setdefault(entry[1], 0);\n",
    "    sec_grouped[entry[1]] = sec_grouped[entry[1]] + 1;\n",
    "print(sec_grouped);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldn_individual_to_lsoa_sec = {};\n",
    "ldn_lsoa_low, ldn_lsoa_mid, ldn_lsoa_high = 0, 0, 0;\n",
    "# match individuals to their lsoas and then to each sec\n",
    "for individual in individuals.values():\n",
    "    if(not individual.get_lsoa()): continue;\n",
    "    if(individual.get_lsoa() not in lsoa_to_sec.keys() and individual.get_in_lambeth() == 0): \n",
    "        continue;\n",
    "    elif(individual.get_lsoa() not in lsoa_to_sec.keys() and individual.get_in_lambeth() == 1):\n",
    "        print('No sec record for lsoa: ' + individual.get_lsoa());\n",
    "        continue;\n",
    "    else:\n",
    "        if(lsoa_to_sec[individual.get_lsoa()] == 'low'): \n",
    "            ldn_lsoa_low += 1;\n",
    "            ldn_individual_to_lsoa_sec[individual.get_id()] = 'low';\n",
    "        elif(lsoa_to_sec[individual.get_lsoa()] == 'mid'): \n",
    "            ldn_lsoa_mid += 1;\n",
    "            ldn_individual_to_lsoa_sec[individual.get_id()] = 'mid';\n",
    "        elif(lsoa_to_sec[individual.get_lsoa()] == 'high'): \n",
    "            ldn_lsoa_high += 1;\n",
    "            ldn_individual_to_lsoa_sec[individual.get_id()] = 'high';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21917 35114 9068\n"
     ]
    }
   ],
   "source": [
    "print(str(ldn_lsoa_low) + ' ' + str(ldn_lsoa_mid) + ' ' + str(ldn_lsoa_high));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldn_lsoa_total = ldn_lsoa_low + ldn_lsoa_mid + ldn_lsoa_high;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDN LSOA low %: 0.33157838999077144\n"
     ]
    }
   ],
   "source": [
    "ldn_lsoa_low_proportion = ldn_lsoa_low / ldn_lsoa_total;\n",
    "print('LDN LSOA low %: ' + str(ldn_lsoa_low_proportion));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDN LSOA mid %: 0.5312334528510265\n"
     ]
    }
   ],
   "source": [
    "ldn_lsoa_mid_proportion = ldn_lsoa_mid / ldn_lsoa_total;\n",
    "print('LDN LSOA mid %: ' + str(ldn_lsoa_mid_proportion));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDN LSOA high %: 0.1371881571582021\n"
     ]
    }
   ],
   "source": [
    "ldn_lsoa_high_proportion = ldn_lsoa_high / ldn_lsoa_total;\n",
    "print('LDN LSOA high %: ' + str(ldn_lsoa_high_proportion));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(ldn_lsoa_low_proportion + ldn_lsoa_mid_proportion + ldn_lsoa_high_proportion);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15160\n"
     ]
    }
   ],
   "source": [
    "# As the dataset contains multiple readings for the same individuals, match to one reading (the latest)\n",
    "patient_to_bmi = {};\n",
    "with open(config.get('data', 'ldn.path_value_clusters'), encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f);\n",
    "    reader_by_date = sorted(reader, key=lambda row: datetime.strptime(row['effectivedate'], '%d/%m/%Y'));\n",
    "    reader_by_date.reverse();\n",
    "    for row in reader_by_date:\n",
    "        if(not row['patient_id'] in patient_to_bmi.keys() and row['numericvalue']):\n",
    "            patient_to_bmi[row['patient_id']] = float(row['numericvalue']);\n",
    "print(len(patient_to_bmi));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 18.0, 3: 17.0, 4: 17.0, 5: 17.0, 6: 17.0, 7: 18.0, 8: 18.0, 9: 19.0, 10: 19.0, 11: 20.0, 12: 21.0, 13: 21.0, 14: 22.0, 15: 23.0, 16: 24.0, 17: 24.0, 18: 25.0}\n",
      "{2: 18.0, 3: 17.0, 4: 17.0, 5: 18.0, 6: 18.0, 7: 18.0, 8: 19.0, 9: 20.0, 10: 20.0, 11: 21.0, 12: 22.0, 13: 23.0, 14: 24.0, 15: 24.0, 16: 25.0, 17: 25.0, 18: 26.0}\n"
     ]
    }
   ],
   "source": [
    "# overweight classification in children is on a sliding scale, so load this data:\n",
    "age_bmi_overweight_boys = {};\n",
    "with open('resources/bmi/boys/age-bmi-overweight.csv') as f:\n",
    "    reader = csv.DictReader(f);\n",
    "    age_bmi_overweight_boys = dict(next(reader));\n",
    "    age_bmi_overweight_boys = dict([int(header), float(cell)] for header, cell in age_bmi_overweight_boys.items());\n",
    "print(age_bmi_overweight_boys);\n",
    "\n",
    "age_bmi_overweight_girls = {};\n",
    "with open('resources/bmi/girls/age-bmi-overweight.csv') as f:\n",
    "    reader = csv.DictReader(f);\n",
    "    age_bmi_overweight_girls = dict(next(reader));\n",
    "    age_bmi_overweight_girls = dict([int(header), float(cell)] for header, cell in age_bmi_overweight_girls.items());\n",
    "print(age_bmi_overweight_girls);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 13.0, 3: 13.0, 4: 13.0, 5: 13.0, 6: 13.0, 7: 13.0, 8: 13.0, 9: 13.0, 10: 13.0, 11: 14.0, 12: 14.0, 13: 15.0, 14: 15.0, 15: 16.0, 16: 16.0, 17: 17.0, 18: 17.0}\n",
      "{2: 13.0, 3: 13.0, 4: 13.0, 5: 13.0, 6: 13.0, 7: 13.0, 8: 13.0, 9: 13.0, 10: 13.0, 11: 14.0, 12: 14.0, 13: 15.0, 14: 15.0, 15: 16.0, 16: 16.0, 17: 16.0, 18: 17.0}\n"
     ]
    }
   ],
   "source": [
    "# overweight classification in children is on a sliding scale, so load this data:\n",
    "age_bmi_underweight_boys = {};\n",
    "with open('resources/bmi/boys/age-bmi-underweight.csv') as f:\n",
    "    reader = csv.DictReader(f);\n",
    "    age_bmi_underweight_boys = dict(next(reader));\n",
    "    age_bmi_underweight_boys = dict([int(header), float(cell)] for header, cell in age_bmi_underweight_boys.items());\n",
    "print(age_bmi_underweight_boys);\n",
    "\n",
    "age_bmi_underweight_girls = {};\n",
    "with open('resources/bmi/girls/age-bmi-underweight.csv') as f:\n",
    "    reader = csv.DictReader(f);\n",
    "    age_bmi_underweight_girls = dict(next(reader));\n",
    "    age_bmi_underweight_girls = dict([int(header), float(cell)] for header, cell in age_bmi_underweight_girls.items());\n",
    "print(age_bmi_underweight_girls);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 38, 3: 98, 4: 108, 5: 145, 6: 153, 7: 166, 8: 157, 9: 136, 10: 170, 11: 177, 12: 198, 13: 228, 14: 248, 15: 267, 16: 276, 17: 345, 18: 317}\n"
     ]
    }
   ],
   "source": [
    "# number of individuals overweight per age (mostly for interest, but also used in final calculation)\n",
    "ldn_individual_to_bmi_sec = {}; \n",
    "def is_overweight(patient_and_bmi):\n",
    "    return patient_and_bmi[1]>=(age_bmi_overweight_boys[individual.get_age()] if individual.get_sex() == 'M' else age_bmi_overweight_girls[individual.get_age()]);\n",
    "\n",
    "age_to_overweight = {};\n",
    "for patient_and_bmi in patient_to_bmi.items():\n",
    "    individual = individuals[patient_and_bmi[0]];\n",
    "    if(individual.get_age() < 2): continue;\n",
    "    age_to_overweight.setdefault(individual.get_age(), 0);\n",
    "    if(is_overweight(patient_and_bmi)):\n",
    "        age_to_overweight[individual.get_age()] = age_to_overweight[individual.get_age()] + 1;\n",
    "        ldn_individual_to_bmi_sec[individual.get_id()] = 'low';\n",
    "print(dict(sorted(age_to_overweight.items())));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 154, 3: 160, 4: 224, 5: 324, 6: 404, 7: 463, 8: 584, 9: 649, 10: 723, 11: 650, 12: 750, 13: 666, 14: 807, 15: 704, 16: 847, 17: 783, 18: 858}\n"
     ]
    }
   ],
   "source": [
    "# number of individuals of a healthy weight per age (mostly for interest, but also used in final calculation)\n",
    "age_to_healthy_weight = {};\n",
    "for patient_and_bmi in patient_to_bmi.items():\n",
    "    individual = individuals[patient_and_bmi[0]];\n",
    "    if(individual.get_age() < 2): continue;\n",
    "    age_to_healthy_weight.setdefault(individual.get_age(), 0);\n",
    "    if((patient_and_bmi[1]<(age_bmi_overweight_boys[individual.get_age()] if individual.get_sex() == 'M' else age_bmi_overweight_girls[individual.get_age()])) and (patient_and_bmi[1]>(age_bmi_underweight_boys[individual.get_age()] if individual.get_sex() == 'M' else age_bmi_underweight_girls[individual.get_age()]))):\n",
    "        age_to_healthy_weight[individual.get_age()] = age_to_healthy_weight[individual.get_age()] + 1;\n",
    "        ldn_individual_to_bmi_sec[individual.get_id()] = 'mid or high';\n",
    "print(dict(sorted(age_to_healthy_weight.items())));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3227\n",
      "9750\n"
     ]
    }
   ],
   "source": [
    "# consider overweight individuals to have a low sec; record others\n",
    "ldn_bmi_low, ldn_bmi_mid, ldn_bmi_high = 0, 0 ,0;\n",
    "ldn_bmi_low = sum(age_to_overweight.values());\n",
    "ldn_bmi_mid_high = sum(age_to_healthy_weight.values());\n",
    "print(ldn_bmi_low);\n",
    "print(ldn_bmi_mid_high);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211\n",
      "3438\n"
     ]
    }
   ],
   "source": [
    "# we also have explicitly coded overweight individuals. add these if they aren't already flagged\n",
    "additional_obese_individuals = [];\n",
    "with open(config.get('data', 'ldn.path_clusters'), encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f);\n",
    "    for row in reader:\n",
    "        if(row['patient_id'] not in additional_obese_individuals and row['cluster']=='OBESITY' and row['patient_id'] in patient_to_bmi.keys() and not is_overweight((row['patient_id'], patient_to_bmi[row['patient_id']]))):\n",
    "            ldn_bmi_low = ldn_bmi_low + 1;\n",
    "            additional_obese_individuals.append(row['patient_id']);\n",
    "print(len(additional_obese_individuals));\n",
    "print(ldn_bmi_low);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4875.0\n",
      "4875.0\n"
     ]
    }
   ],
   "source": [
    "# we can't necessarily make a link between being of a healthy weight and a mid/high SEC, so distribute evenly:\n",
    "ldn_bmi_mid = ldn_bmi_mid_high / 2;\n",
    "ldn_bmi_high = ldn_bmi_mid_high / 2;\n",
    "print(ldn_bmi_mid);\n",
    "print(ldn_bmi_high);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldn_bmi_total = ldn_bmi_low + ldn_bmi_mid + ldn_bmi_high;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDN BMI low %: 0.2606915377616015\n"
     ]
    }
   ],
   "source": [
    "ldn_bmi_low_proportion = ldn_bmi_low / ldn_bmi_total;\n",
    "print('LDN BMI low %: ' + str(ldn_bmi_low_proportion));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDN BMI mid %: 0.36965423111919926\n"
     ]
    }
   ],
   "source": [
    "ldn_bmi_mid_proportion = ldn_bmi_mid / ldn_bmi_total;\n",
    "print('LDN BMI mid %: ' + str(ldn_bmi_mid_proportion));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDN BMI high %: 0.36965423111919926\n"
     ]
    }
   ],
   "source": [
    "ldn_bmi_high_proportion = ldn_bmi_high / ldn_bmi_total;\n",
    "print('LDN BMI high %: ' + str(ldn_bmi_high_proportion));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(ldn_bmi_low_proportion + ldn_bmi_mid_proportion + ldn_bmi_high_proportion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8972\n",
      "9192\n"
     ]
    }
   ],
   "source": [
    "ldn_covid_low, ldn_covid_mid, ldn_covid_high = 0, 0, 0;\n",
    "patient_to_covid = {};\n",
    "ldn_covid_mid_high = 0;\n",
    "ldn_individual_to_covid_sec = {};\n",
    "with open(config.get('data', 'ldn.path_covid'), encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f);\n",
    "    reader_by_date = sorted(reader, key=lambda row: datetime.strptime(row['effectivedate'], '%Y-%m-%d'));\n",
    "    reader_by_date.reverse();\n",
    "    for row in reader_by_date:\n",
    "        if('CONF' in row['cluster'] and not row['patient_id'] in patient_to_covid.keys()):\n",
    "            ldn_covid_low = ldn_covid_low + 1;\n",
    "            patient_to_covid[row['patient_id']] = True;\n",
    "            ldn_individual_to_covid_sec[row['patient_id']] = 'low';\n",
    "        elif('NEGATIVE' in row['cluster'] and not row['patient_id'] in patient_to_covid.keys()):\n",
    "            ldn_covid_mid_high = ldn_covid_mid_high + 1;\n",
    "            patient_to_covid[row['patient_id']] = False;\n",
    "            ldn_individual_to_covid_sec[row['patient_id']] = 'mid or high';\n",
    "print(ldn_covid_low);\n",
    "print(ldn_covid_mid_high);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4596.0\n"
     ]
    }
   ],
   "source": [
    "ldn_covid_mid = ldn_covid_mid_high / 2;\n",
    "ldn_covid_high = ldn_covid_mid_high / 2;\n",
    "print(ldn_covid_mid);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldn_covid_total = ldn_covid_low + ldn_covid_mid + ldn_covid_high;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDN COVID low %: 0.4939440651838802\n"
     ]
    }
   ],
   "source": [
    "ldn_covid_low_proportion = ldn_covid_low / ldn_covid_total;\n",
    "print('LDN COVID low %: ' + str(ldn_covid_low_proportion));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDN COVID mid %: 0.2530279674080599\n"
     ]
    }
   ],
   "source": [
    "ldn_covid_mid_proportion = ldn_covid_mid / ldn_covid_total;\n",
    "print('LDN COVID mid %: ' + str(ldn_covid_mid_proportion));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDN COVID high %: 0.2530279674080599\n"
     ]
    }
   ],
   "source": [
    "ldn_covid_high_proportion = ldn_covid_high / ldn_covid_total;\n",
    "print('LDN COVID high %: ' + str(ldn_covid_high_proportion));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "print(ldn_covid_low_proportion + ldn_covid_mid_proportion + ldn_covid_high_proportion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36207133097875105\n"
     ]
    }
   ],
   "source": [
    "# take average of three SEC measures from LDN\n",
    "ldn_sec_low_proportion = (ldn_lsoa_low_proportion + ldn_bmi_low_proportion + ldn_covid_low_proportion) / 3;\n",
    "print(ldn_sec_low_proportion);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3846385504594285\n"
     ]
    }
   ],
   "source": [
    "ldn_sec_mid_proportion = (ldn_lsoa_mid_proportion + ldn_bmi_mid_proportion + ldn_covid_mid_proportion) / 3;\n",
    "print(ldn_sec_mid_proportion);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25329011856182043\n"
     ]
    }
   ],
   "source": [
    "ldn_sec_high_proportion = (ldn_lsoa_high_proportion + ldn_bmi_high_proportion + ldn_covid_high_proportion) / 3;\n",
    "print(ldn_sec_high_proportion);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# double check == 1\n",
    "print(ldn_sec_low_proportion + ldn_sec_mid_proportion + ldn_sec_high_proportion);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDN low SEC: 36\n",
      "LDN mid SEC: 38\n",
      "LDN high SEC: 25\n"
     ]
    }
   ],
   "source": [
    "# aggregate for /100\n",
    "ldn_sec_low_proportion_100 = max(1, int(round(ldn_sec_low_proportion, 2) * 100));\n",
    "print(\"LDN low SEC: \" + str(ldn_sec_low_proportion_100));\n",
    "ldn_sec_mid_proportion_100 = max(1, int(round(ldn_sec_mid_proportion, 2) * 100));\n",
    "print(\"LDN mid SEC: \" + str(ldn_sec_mid_proportion_100));\n",
    "ldn_sec_high_proportion_100 = max(1, int(round(ldn_sec_high_proportion, 2) * 100));\n",
    "print(\"LDN high SEC: \" + str(ldn_sec_high_proportion_100));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "print(ldn_sec_low_proportion_100 + ldn_sec_mid_proportion_100 + ldn_sec_high_proportion_100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Ethnicity</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13962 29336\n"
     ]
    }
   ],
   "source": [
    "# combine two ethnicity terms to identify two groups\n",
    "ldn_ethnicity_white_british, ldn_ethnicity_minority = 0, 0;\n",
    "ldn_individual_to_ethnicity = {};\n",
    "\n",
    "for individual in individuals.values():\n",
    "    if(not individual.get_ethnicity_a() or not individual.get_ethnicity_b()): continue;\n",
    "    if(individual.get_ethnicity_a()==1 and individual.get_ethnicity_b()==1):\n",
    "        ldn_ethnicity_white_british = ldn_ethnicity_white_british + 1;\n",
    "        ldn_individual_to_ethnicity[individual.get_id()] = 'white british';\n",
    "    elif(individual.get_ethnicity_a()>1 and individual.get_ethnicity_a()<=5 and  individual.get_ethnicity_b()>1 and individual.get_ethnicity_b()<=18):\n",
    "        ldn_ethnicity_minority = ldn_ethnicity_minority + 1;\n",
    "        ldn_individual_to_ethnicity[individual.get_id()] = 'ethnic minority';\n",
    "\n",
    "print(str(ldn_ethnicity_white_british) + ' ' + str(ldn_ethnicity_minority));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43298\n"
     ]
    }
   ],
   "source": [
    "ldn_ethnicity_total = ldn_ethnicity_white_british + ldn_ethnicity_minority;\n",
    "print(ldn_ethnicity_total);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3224629313132246 0.6775370686867753\n"
     ]
    }
   ],
   "source": [
    "ldn_ethnicity_white_british_proportion = ldn_ethnicity_white_british / ldn_ethnicity_total;\n",
    "ldn_ethnicity_minority_proportion = ldn_ethnicity_minority / ldn_ethnicity_total;\n",
    "print(str(ldn_ethnicity_white_british_proportion) + ' ' + str(ldn_ethnicity_minority_proportion));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDN white british: 32\n",
      "LDN minority ethnic: 68\n"
     ]
    }
   ],
   "source": [
    "ldn_ethnicity_white_british_proportion_100 = max(1, int(round(ldn_ethnicity_white_british_proportion, 2) * 100));\n",
    "print(\"LDN white british: \" + str(ldn_ethnicity_white_british_proportion_100));\n",
    "ldn_ethnicity_minority_proportion_100 = max(1, int(round(ldn_ethnicity_minority_proportion, 2) * 100));\n",
    "print(\"LDN minority ethnic: \" + str(ldn_ethnicity_minority_proportion_100));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(ldn_ethnicity_white_british_proportion_100 + ldn_ethnicity_minority_proportion_100);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Asthma</h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that attempts to gain consensus on SEC across the three metrics\n",
    "def get_LDN_SEC(patient_id):\n",
    "    classifications = [ldn_individual_to_lsoa_sec[patient_id] if patient_id in ldn_individual_to_lsoa_sec.keys() else \"\", ldn_individual_to_bmi_sec[patient_id] if patient_id in ldn_individual_to_bmi_sec.keys() else \"\", ldn_individual_to_covid_sec[patient_id] if patient_id in ldn_individual_to_covid_sec.keys() else \"\"];\n",
    "    classifications_split = [item for sublist in list(map(lambda classification: classification.split(' or '), classifications)) for item in sublist];\n",
    "    counts = {'low':classifications_split.count('low'), 'mid':classifications_split.count('mid'), 'high':classifications_split.count('high')};\n",
    "    max_counts = [sec for sec, count in counts.items() if count == max(counts.values())];\n",
    "    if(len(max_counts) == 1): return max_counts[0];\n",
    "    elif(len(max_counts) == 2 and max_counts == [\"low\", \"high\"]): return \"mid\";\n",
    "    return False;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4342\n",
      "22394\n"
     ]
    }
   ],
   "source": [
    "asthma_patients = [];\n",
    "other_patients = [];\n",
    "with open(config.get('data', 'ldn.path_clusters'), encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f);\n",
    "    reader_by_date = sorted(reader, key=lambda row: datetime.strptime(row['effectivedate'], '%Y-%m-%d'));\n",
    "    reader_by_date.reverse();\n",
    "    for row in reader_by_date:\n",
    "        if('AST' in row['cluster'] and not row['patient_id'] in asthma_patients):\n",
    "            asthma_patients.append(row['patient_id']);\n",
    "        elif(not 'AST' in row['cluster'] and not row['patient_id'] in asthma_patients and not row['patient_id'] in other_patients):\n",
    "            other_patients.append(row['patient_id']);\n",
    "# For interest\n",
    "print(len(asthma_patients));\n",
    "print(len(other_patients));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1031\n",
      "1871\n",
      "371\n",
      "6175\n",
      "9453\n",
      "2011\n"
     ]
    }
   ],
   "source": [
    "# Determine population of 6 groups of interest\n",
    "ldn_sec_low_asthma_proportion, ldn_sec_mid_asthma_proportion, ldn_sec_high_asthma_proportion, ldn_sec_low_non_asthma_proportion, ldn_sec_mid_non_asthma_proportion, ldn_sec_high_non_asthma_proportion = 0, 0, 0, 0, 0, 0;\n",
    "ldn_sec_low_asthma_individuals, ldn_sec_mid_asthma_individuals, ldn_sec_high_asthma_individuals, ldn_sec_low_non_asthma_individuals, ldn_sec_mid_non_asthma_individuals, ldn_sec_high_non_asthma_individuals = [], [], [], [], [], [];\n",
    "for individual in individuals.values():\n",
    "    sec = get_LDN_SEC(individual.get_id());\n",
    "    if(sec):\n",
    "        if(individual.get_id() in asthma_patients and sec=='low'):\n",
    "            ldn_sec_low_asthma_proportion = ldn_sec_low_asthma_proportion + 1;\n",
    "            ldn_sec_low_asthma_individuals.append(individual.get_id());\n",
    "        elif(individual.get_id() in asthma_patients and sec=='mid'):\n",
    "            ldn_sec_mid_asthma_proportion = ldn_sec_mid_asthma_proportion + 1;\n",
    "            ldn_sec_mid_asthma_individuals.append(individual.get_id());\n",
    "        elif(individual.get_id() in asthma_patients and sec=='high'):\n",
    "            ldn_sec_high_asthma_proportion = ldn_sec_high_asthma_proportion + 1;\n",
    "            ldn_sec_high_asthma_individuals.append(individual.get_id());\n",
    "        elif(individual.get_id() in other_patients and sec=='low'):\n",
    "            ldn_sec_low_non_asthma_proportion = ldn_sec_low_non_asthma_proportion + 1;\n",
    "            ldn_sec_low_non_asthma_individuals.append(individual.get_id());\n",
    "        elif(individual.get_id() in other_patients and sec=='mid'):\n",
    "            ldn_sec_mid_non_asthma_proportion = ldn_sec_mid_non_asthma_proportion + 1;\n",
    "            ldn_sec_mid_non_asthma_individuals.append(individual.get_id());\n",
    "        elif(individual.get_id() in other_patients and sec=='high'):\n",
    "            ldn_sec_high_non_asthma_proportion = ldn_sec_high_non_asthma_proportion + 1;\n",
    "            ldn_sec_high_non_asthma_individuals.append(individual.get_id());\n",
    "\n",
    "print(ldn_sec_low_asthma_proportion); \n",
    "print(ldn_sec_mid_asthma_proportion); \n",
    "print(ldn_sec_high_asthma_proportion); \n",
    "print(ldn_sec_low_non_asthma_proportion);\n",
    "print(ldn_sec_mid_non_asthma_proportion); \n",
    "print(ldn_sec_high_non_asthma_proportion);\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldn_sec_asthma_total = ldn_sec_low_asthma_proportion + ldn_sec_mid_asthma_proportion + ldn_sec_high_asthma_proportion + ldn_sec_low_non_asthma_proportion + ldn_sec_mid_non_asthma_proportion + ldn_sec_high_non_asthma_proportion;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDN low SEC + asthma: 5\n",
      "LDN mid SEC + asthma: 9\n",
      "LDN high SEC + asthma: 2\n",
      "LDN low SEC: 30\n",
      "LDN mid SEC: 45\n",
      "LDN high SEC: 10\n"
     ]
    }
   ],
   "source": [
    "ldn_sec_low_asthma_proportion_100 = max(1, int(round(ldn_sec_low_asthma_proportion / ldn_sec_asthma_total, 2) * 100));\n",
    "print(\"LDN low SEC + asthma: \" + str(ldn_sec_low_asthma_proportion_100));\n",
    "ldn_sec_mid_asthma_proportion_100 = max(1, int(round(ldn_sec_mid_asthma_proportion / ldn_sec_asthma_total, 2) * 100));\n",
    "print(\"LDN mid SEC + asthma: \" + str(ldn_sec_mid_asthma_proportion_100));\n",
    "ldn_sec_high_asthma_proportion_100 = max(1, int(round(ldn_sec_high_asthma_proportion / ldn_sec_asthma_total, 2) * 100));\n",
    "print(\"LDN high SEC + asthma: \" + str(ldn_sec_high_asthma_proportion_100));\n",
    "ldn_sec_low_non_asthma_proportion_100 = max(1, int(round(ldn_sec_low_non_asthma_proportion / ldn_sec_asthma_total, 2) * 100));\n",
    "print(\"LDN low SEC: \" + str(ldn_sec_low_non_asthma_proportion_100));\n",
    "ldn_sec_mid_non_asthma_proportion_100 = max(1, int(round(ldn_sec_mid_non_asthma_proportion / ldn_sec_asthma_total, 2) * 100));\n",
    "print(\"LDN mid SEC: \" + str(ldn_sec_mid_non_asthma_proportion_100));\n",
    "ldn_sec_high_non_asthma_proportion_100 = max(1, int(round(ldn_sec_high_non_asthma_proportion / ldn_sec_asthma_total, 2) * 100));\n",
    "print(\"LDN high SEC: \" + str(ldn_sec_high_non_asthma_proportion_100));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "print(ldn_sec_low_asthma_proportion_100 + ldn_sec_mid_asthma_proportion_100 + ldn_sec_high_asthma_proportion_100 + ldn_sec_low_non_asthma_proportion_100 + ldn_sec_mid_non_asthma_proportion_100 + ldn_sec_high_non_asthma_proportion_100);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "824\n",
      "2390\n",
      "4163\n",
      "10882\n"
     ]
    }
   ],
   "source": [
    "# Determine population of 4 groups of interest\n",
    "ldn_ethnicity_white_asthma_proportion, ldn_ethnicity_minority_asthma_proportion, ldn_ethnicity_white_non_asthma_proportion, ldn_ethnicity_minority_non_asthma_proportion = 0, 0, 0, 0;\n",
    "ldn_ethnicity_white_asthma_individuals, ldn_ethnicity_minority_asthma_individuals, ldn_ethnicity_white_non_asthma_individuals, ldn_ethnicity_minority_non_asthma_individuals = [], [], [], [];\n",
    "for individual in individuals.values():\n",
    "    if(not individual.get_id() in ldn_individual_to_ethnicity.keys()): continue;\n",
    "    ethnicity = ldn_individual_to_ethnicity[individual.get_id()];\n",
    "    if(ethnicity):\n",
    "        if(individual.get_id() in asthma_patients and ethnicity=='white british'):\n",
    "            ldn_ethnicity_white_asthma_proportion = ldn_ethnicity_white_asthma_proportion + 1;\n",
    "            ldn_ethnicity_white_asthma_individuals.append(individual.get_id());\n",
    "        elif(individual.get_id() in asthma_patients and ethnicity=='ethnic minority'):\n",
    "            ldn_ethnicity_minority_asthma_proportion = ldn_ethnicity_minority_asthma_proportion + 1;\n",
    "            ldn_ethnicity_minority_asthma_individuals.append(individual.get_id());\n",
    "        elif(individual.get_id() in other_patients and ethnicity=='white british'):\n",
    "            ldn_ethnicity_white_non_asthma_proportion = ldn_ethnicity_white_non_asthma_proportion + 1;\n",
    "            ldn_ethnicity_white_non_asthma_individuals.append(individual.get_id());\n",
    "        elif(individual.get_id() in other_patients and ethnicity=='ethnic minority'):\n",
    "            ldn_ethnicity_minority_non_asthma_proportion = ldn_ethnicity_minority_non_asthma_proportion + 1;\n",
    "            ldn_ethnicity_minority_non_asthma_individuals.append(individual.get_id());\n",
    "\n",
    "print(ldn_ethnicity_white_asthma_proportion); \n",
    "print(ldn_ethnicity_minority_asthma_proportion); \n",
    "print(ldn_ethnicity_white_non_asthma_proportion); \n",
    "print(ldn_ethnicity_minority_non_asthma_proportion);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldn_ethnicity_asthma_total = ldn_ethnicity_white_asthma_proportion + ldn_ethnicity_minority_asthma_proportion + ldn_ethnicity_white_non_asthma_proportion + ldn_ethnicity_minority_non_asthma_proportion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDN minority ethnic + asthma: 9\n",
      "LDN white british + asthma: 5\n",
      "LDN minority ethnic: 60\n",
      "LDN white british: 30\n"
     ]
    }
   ],
   "source": [
    "ldn_ethnicity_minority_asthma_proportion_100 = max(1, int(round(ldn_ethnicity_minority_asthma_proportion / ldn_ethnicity_asthma_total, 2) * 100));\n",
    "print(\"LDN minority ethnic + asthma: \" + str(ldn_sec_mid_asthma_proportion_100));\n",
    "ldn_ethnicity_white_asthma_proportion_100 = max(1, int(round(ldn_ethnicity_white_asthma_proportion / ldn_ethnicity_asthma_total, 2) * 100));\n",
    "print(\"LDN white british + asthma: \" + str(ldn_sec_low_asthma_proportion_100));\n",
    "ldn_ethnicity_minority_non_asthma_proportion_100 = max(1, int(round(ldn_ethnicity_minority_non_asthma_proportion / ldn_ethnicity_asthma_total, 2) * 100));\n",
    "print(\"LDN minority ethnic: \" + str(ldn_ethnicity_minority_non_asthma_proportion_100));\n",
    "ldn_ethnicity_white_non_asthma_proportion_100 = max(1, int(round(ldn_ethnicity_white_non_asthma_proportion / ldn_ethnicity_asthma_total, 2) * 100));\n",
    "print(\"LDN white british: \" + str(ldn_sec_low_non_asthma_proportion_100));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "print(ldn_ethnicity_white_asthma_proportion_100 + ldn_ethnicity_minority_asthma_proportion_100 + ldn_ethnicity_white_non_asthma_proportion_100 + ldn_ethnicity_minority_non_asthma_proportion_100);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Health utilisation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_winter(month):\n",
    "    if(month==12 or month==1 or month==2): return True;\n",
    "    return False;\n",
    "\n",
    "def get_total_utilisation(row):\n",
    "    utilisation_keys = ['gp_f2f', 'gp_tel', 'gp_hv', 'gp_ett', 'nurse_f2f', 'nurse_tel', 'nurse_hv', 'nurse_ett', 'ohcpuc_f2f', 'ohcpuc_tel', 'ohcpuc_hv', 'ohcpuc_ett'];\n",
    "    return sum(dict(map(lambda cell:(cell[0],int(cell[1])), filter(lambda cell:cell[0] in utilisation_keys, row.items()))).values());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2018': 41612, '2017': 12426, '2019': 47488, '2020': 49244, '2021': 57936, '2022': 29718} {'2017': 99066, '2018': 118186, '2019': 131553, '2020': 140171, '2021': 205833}\n"
     ]
    }
   ],
   "source": [
    "# for interest\n",
    "# compare utilisation in winter months with rest of year\n",
    "year_to_utilisation_winter = {};\n",
    "year_to_utilisation_other = {};\n",
    "with open(config.get('data', 'ldn.path_consultations'), encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f);\n",
    "    for row in reader:\n",
    "        total_utilisation = get_total_utilisation(row);\n",
    "        if(is_winter(int(row['con_month']))):\n",
    "            year_to_utilisation_winter[row['con_year']] = year_to_utilisation_winter.setdefault(row['con_year'], 0) + total_utilisation;\n",
    "        else:\n",
    "            year_to_utilisation_other[row['con_year']] = year_to_utilisation_other.setdefault(row['con_year'], 0) + total_utilisation;\n",
    "\n",
    "print(str(year_to_utilisation_winter) + ' ' + str(year_to_utilisation_other));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39737.333333333336\n",
      "138961.8\n"
     ]
    }
   ],
   "source": [
    "print(sum(year_to_utilisation_winter.values())/len(year_to_utilisation_winter.values()));\n",
    "print(sum(year_to_utilisation_other.values())/len(year_to_utilisation_other.values()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_utilisation_sec_asthma(patient_id, year, ldn_utilisation, total_utilisation):\n",
    "    ldn_utilisation.setdefault(year, {});\n",
    "    if(patient_id in ldn_sec_low_asthma_individuals):\n",
    "        ldn_utilisation[row['con_year']].setdefault('sec_low_asthma', []).append(total_utilisation);\n",
    "    elif(patient_id in ldn_sec_mid_asthma_individuals):\n",
    "        ldn_utilisation[row['con_year']].setdefault('sec_mid_asthma', []).append(total_utilisation);\n",
    "    elif(patient_id in ldn_sec_high_asthma_individuals):\n",
    "        ldn_utilisation[row['con_year']].setdefault('sec_high_asthma', []).append(total_utilisation);\n",
    "    elif(patient_id in ldn_sec_low_non_asthma_individuals):\n",
    "        ldn_utilisation[row['con_year']].setdefault('sec_low_non_asthma', []).append(total_utilisation);\n",
    "    elif(patient_id in ldn_sec_mid_non_asthma_individuals):\n",
    "        ldn_utilisation[row['con_year']].setdefault('sec_mid_non_asthma', []).append(total_utilisation);\n",
    "    elif(patient_id in ldn_sec_high_non_asthma_individuals):\n",
    "        ldn_utilisation[row['con_year']].setdefault('sec_high_non_asthma', []).append(total_utilisation);\n",
    "\n",
    "def record_utilisation_ethnicity_asthma(patient_id, year, ldn_utilisation, total_utilisation):\n",
    "    ldn_utilisation.setdefault(year, {});\n",
    "    if(patient_id in ldn_ethnicity_white_asthma_individuals):\n",
    "        ldn_utilisation[row['con_year']].setdefault('ethnicity_white_asthma', []).append(total_utilisation);\n",
    "    elif(patient_id in ldn_ethnicity_minority_asthma_individuals):\n",
    "        ldn_utilisation[row['con_year']].setdefault('ethnicity_minority_asthma', []).append(total_utilisation);\n",
    "    elif(patient_id in ldn_ethnicity_white_non_asthma_individuals):\n",
    "        ldn_utilisation[row['con_year']].setdefault('ethnicity_white_non_asthma', []).append(total_utilisation);\n",
    "    elif(patient_id in ldn_ethnicity_minority_non_asthma_individuals):\n",
    "        ldn_utilisation[row['con_year']].setdefault('ethnicity_minority_non_asthma', []).append(total_utilisation);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break down utilisation by each group above\n",
    "ldn_utilisation_winter = {};\n",
    "ldn_utilisation_other = {};\n",
    "\n",
    "with open(config.get('data', 'ldn.path_consultations'), encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f);\n",
    "    for row in reader:\n",
    "        total_utilisation = get_total_utilisation(row);\n",
    "        patient_id = row['patient_id'];\n",
    "        if(is_winter(int(row['con_month']))): \n",
    "            record_utilisation_sec_asthma(patient_id, row['con_year'], ldn_utilisation_winter, total_utilisation);\n",
    "            record_utilisation_ethnicity_asthma(patient_id, row['con_year'], ldn_utilisation_winter, total_utilisation);\n",
    "        else: \n",
    "            record_utilisation_sec_asthma(patient_id, row['con_year'], ldn_utilisation_other, total_utilisation);\n",
    "            record_utilisation_ethnicity_asthma(patient_id, row['con_year'], ldn_utilisation_other, total_utilisation);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2018': {'ethnicity_white_non_asthma': 1.55718879191548, 'sec_mid_non_asthma': 1.5250719276613234, 'ethnicity_minority_non_asthma': 1.489612676056338, 'sec_high_asthma': 1.5304347826086957, 'ethnicity_minority_asthma': 1.5448504983388704, 'sec_low_non_asthma': 1.4891304347826086, 'sec_mid_asthma': 1.5613040396881643, 'sec_low_asthma': 1.6243654822335025, 'ethnicity_white_asthma': 1.5884244372990353, 'sec_high_non_asthma': 1.5828402366863905}, '2017': {'sec_mid_non_asthma': 1.5130434782608695, 'ethnicity_minority_non_asthma': 1.490096208262592, 'sec_high_asthma': 1.295774647887324, 'ethnicity_minority_asthma': 1.5156794425087108, 'sec_mid_asthma': 1.5601750547045952, 'sec_low_non_asthma': 1.4771739130434782, 'sec_low_asthma': 1.4067796610169492, 'sec_high_non_asthma': 1.5521472392638036, 'ethnicity_white_non_asthma': 1.5093795093795095, 'ethnicity_white_asthma': 1.4564102564102563}, '2019': {'sec_mid_non_asthma': 1.561774616248596, 'ethnicity_minority_non_asthma': 1.5178600554558799, 'ethnicity_white_non_asthma': 1.6147433084686267, 'sec_high_asthma': 1.6285714285714286, 'ethnicity_minority_asthma': 1.539210661199385, 'sec_low_non_asthma': 1.5245098039215685, 'sec_high_non_asthma': 1.6009615384615385, 'sec_mid_asthma': 1.5363391655450875, 'sec_low_asthma': 1.6025, 'ethnicity_white_asthma': 1.6419213973799127}, '2020': {'sec_mid_non_asthma': 1.6778391167192428, 'ethnicity_minority_non_asthma': 1.633356790992259, 'sec_high_asthma': 1.5797665369649805, 'ethnicity_minority_asthma': 1.5958795562599049, 'sec_high_non_asthma': 1.596646942800789, 'sec_mid_asthma': 1.5526866713189114, 'ethnicity_white_non_asthma': 1.675793133420252, 'sec_low_asthma': 1.7157622739018088, 'ethnicity_white_asthma': 1.6345840130505709, 'sec_low_non_asthma': 1.6601848900223144}, '2021': {'sec_mid_non_asthma': 1.826830249396621, 'ethnicity_minority_non_asthma': 1.7604203152364273, 'sec_high_non_asthma': 1.808349146110057, 'sec_high_asthma': 1.7672413793103448, 'ethnicity_minority_asthma': 1.7687315634218288, 'sec_low_non_asthma': 1.7840046701692935, 'sec_mid_asthma': 1.7698229407236337, 'sec_low_asthma': 1.756720430107527, 'ethnicity_white_asthma': 1.9172297297297298, 'ethnicity_white_non_asthma': 1.886031042128603}, '2022': {'sec_high_asthma': 2.1875, 'ethnicity_minority_asthma': 1.9733333333333334, 'sec_high_non_asthma': 1.9645390070921986, 'ethnicity_minority_non_asthma': 1.8644408688656475, 'sec_mid_asthma': 2.003669724770642, 'sec_low_non_asthma': 1.9144862795149968, 'sec_low_asthma': 2.1021505376344085, 'ethnicity_white_asthma': 2.2698412698412698, 'ethnicity_white_non_asthma': 2.0341796875, 'sec_mid_non_asthma': 1.9432191459408727}}\n",
      "{'2017': {'sec_mid_non_asthma': 1.497753451515399, 'ethnicity_minority_non_asthma': 1.4650351994636273, 'ethnicity_white_non_asthma': 1.501382998340402, 'sec_low_non_asthma': 1.4284407267023917, 'sec_high_asthma': 1.464339908952959, 'ethnicity_minority_asthma': 1.467386700550614, 'sec_mid_asthma': 1.4847552447552448, 'sec_low_asthma': 1.4180967238689548, 'sec_high_non_asthma': 1.5299844236760125, 'ethnicity_white_asthma': 1.4508086253369272}, '2018': {'sec_mid_non_asthma': 1.5281428571428572, 'ethnicity_minority_non_asthma': 1.4988165321357043, 'ethnicity_white_non_asthma': 1.519360685450651, 'sec_low_non_asthma': 1.4726287887518728, 'sec_mid_asthma': 1.4994853319608852, 'ethnicity_minority_asthma': 1.5032497678737233, 'sec_low_asthma': 1.5444870157513835, 'sec_high_asthma': 1.5191256830601092, 'sec_high_non_asthma': 1.5452638937434464, 'ethnicity_white_asthma': 1.5617391304347825}, '2019': {'sec_low_non_asthma': 1.472961373390558, 'sec_high_non_asthma': 1.5560842963970087, 'ethnicity_minority_non_asthma': 1.4861768226643106, 'sec_high_asthma': 1.5868983957219251, 'ethnicity_minority_asthma': 1.4848032817452919, 'sec_mid_asthma': 1.4862705941088368, 'sec_low_asthma': 1.4881325570980743, 'sec_mid_non_asthma': 1.5390748550342646, 'ethnicity_white_non_asthma': 1.5413590477625434, 'ethnicity_white_asthma': 1.5468577728776185}, '2020': {'sec_mid_asthma': 1.743433271424781, 'ethnicity_minority_asthma': 1.7964156262585582, 'sec_high_asthma': 1.8282694848084544, 'sec_high_non_asthma': 1.9271653543307086, 'ethnicity_white_non_asthma': 1.9520571234274056, 'sec_low_non_asthma': 1.936870642912471, 'ethnicity_minority_non_asthma': 1.884902411021814, 'sec_low_asthma': 1.8859315589353611, 'ethnicity_white_asthma': 1.8895315211104684, 'sec_mid_non_asthma': 1.9124035325005968}, '2021': {'sec_mid_non_asthma': 1.9208827327151075, 'ethnicity_minority_non_asthma': 1.8959871088470734, 'sec_high_asthma': 1.8978365384615385, 'ethnicity_minority_asthma': 1.8788689978249957, 'sec_low_asthma': 1.9530125047366427, 'sec_high_non_asthma': 1.9120521172638436, 'ethnicity_white_non_asthma': 1.9550663061671172, 'sec_low_non_asthma': 1.8912636922254875, 'sec_mid_asthma': 1.8700974835638178, 'ethnicity_white_asthma': 1.9086444007858545}}\n"
     ]
    }
   ],
   "source": [
    "# Get average visits per person per year within each group\n",
    "ldn_utilisation_winter_average = dict(map(lambda year_entries:(year_entries[0], dict(map(lambda group_entries:(group_entries[0], sum(group_entries[1])/len(group_entries[1])), year_entries[1].items()))), ldn_utilisation_winter.items()));\n",
    "ldn_utilisation_other_average = dict(map(lambda year_entries:(year_entries[0], dict(map(lambda group_entries:(group_entries[0], sum(group_entries[1])/len(group_entries[1])), year_entries[1].items()))), ldn_utilisation_other.items()));\n",
    "print(ldn_utilisation_winter_average);\n",
    "print(ldn_utilisation_other_average);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7013797308156995\n",
      "1.6639995994585057\n",
      "1.6648814625571289\n",
      "1.641581665242377\n",
      "1.6746297557045875\n",
      "1.6842473517357963\n"
     ]
    }
   ],
   "source": [
    "# Winter, SEC + asthma\n",
    "# Average utilisation across the years\n",
    "sec_low_asthma_utilisation_winter = sum(list(map(lambda year:year['sec_low_asthma'], ldn_utilisation_winter_average.values()))) / len(ldn_utilisation_winter_average.values());\n",
    "print(sec_low_asthma_utilisation_winter);\n",
    "\n",
    "sec_mid_asthma_utilisation_winter = sum(list(map(lambda year:year['sec_mid_asthma'], ldn_utilisation_winter_average.values()))) / len(ldn_utilisation_winter_average.values());\n",
    "print(sec_mid_asthma_utilisation_winter);\n",
    "\n",
    "sec_high_asthma_utilisation_winter = sum(list(map(lambda year:year['sec_high_asthma'], ldn_utilisation_winter_average.values()))) / len(ldn_utilisation_winter_average.values());\n",
    "print(sec_high_asthma_utilisation_winter);\n",
    "\n",
    "sec_low_non_asthma_utilisation_winter = sum(list(map(lambda year:year['sec_low_non_asthma'], ldn_utilisation_winter_average.values()))) / len(ldn_utilisation_winter_average.values());\n",
    "print(sec_low_non_asthma_utilisation_winter);\n",
    "\n",
    "sec_mid_non_asthma_utilisation_winter = sum(list(map(lambda year:year['sec_mid_non_asthma'], ldn_utilisation_winter_average.values()))) / len(ldn_utilisation_winter_average.values());\n",
    "print(sec_mid_non_asthma_utilisation_winter);\n",
    "\n",
    "sec_high_non_asthma_utilisation_winter = sum(list(map(lambda year:year['sec_high_non_asthma'], ldn_utilisation_winter_average.values()))) / len(ldn_utilisation_winter_average.values());\n",
    "print(sec_high_non_asthma_utilisation_winter);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7514018506184623\n",
      "1.6562808425103388\n",
      "1.7128859121354119\n",
      "1.6259644858115239\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Winter, ethnicity + asthma\n",
    "print(sum(list(map(lambda year:year['ethnicity_white_asthma'], ldn_utilisation_winter_average.values()))) / len(ldn_utilisation_winter_average.values()));\n",
    "print(sum(list(map(lambda year:year['ethnicity_minority_asthma'], ldn_utilisation_winter_average.values()))) / len(ldn_utilisation_winter_average.values()));\n",
    "print(sum(list(map(lambda year:year['ethnicity_white_non_asthma'], ldn_utilisation_winter_average.values()))) / len(ldn_utilisation_winter_average.values()));\n",
    "print(sum(list(map(lambda year:year['ethnicity_minority_non_asthma'], ldn_utilisation_winter_average.values()))) / len(ldn_utilisation_winter_average.values()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6579320720780832\n",
      "1.616808385162713\n",
      "1.6592940022009972\n",
      "1.6404330447965563\n",
      "1.6796514857816451\n",
      "1.6941100170822039\n"
     ]
    }
   ],
   "source": [
    "# Other months, SEC + asthma\n",
    "print(sum(list(map(lambda year:year['sec_low_asthma'], ldn_utilisation_other_average.values()))) / len(ldn_utilisation_other_average.values()));\n",
    "print(sum(list(map(lambda year:year['sec_mid_asthma'], ldn_utilisation_other_average.values()))) / len(ldn_utilisation_other_average.values()));\n",
    "print(sum(list(map(lambda year:year['sec_high_asthma'], ldn_utilisation_other_average.values()))) / len(ldn_utilisation_other_average.values()));\n",
    "print(sum(list(map(lambda year:year['sec_low_non_asthma'], ldn_utilisation_other_average.values()))) / len(ldn_utilisation_other_average.values()));\n",
    "print(sum(list(map(lambda year:year['sec_mid_non_asthma'], ldn_utilisation_other_average.values()))) / len(ldn_utilisation_other_average.values()));\n",
    "print(sum(list(map(lambda year:year['sec_high_non_asthma'], ldn_utilisation_other_average.values()))) / len(ldn_utilisation_other_average.values()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6261448748506369\n",
      "1.6715162901091305\n",
      "1.6461836148265057\n",
      "1.6938452322296236\n"
     ]
    }
   ],
   "source": [
    "# Other months, ethnicity + asthma\n",
    "print(sum(list(map(lambda year:year['ethnicity_minority_asthma'], ldn_utilisation_other_average.values()))) / len(ldn_utilisation_other_average.values()));\n",
    "print(sum(list(map(lambda year:year['ethnicity_white_asthma'], ldn_utilisation_other_average.values()))) / len(ldn_utilisation_other_average.values()));\n",
    "print(sum(list(map(lambda year:year['ethnicity_minority_non_asthma'], ldn_utilisation_other_average.values()))) / len(ldn_utilisation_other_average.values()));\n",
    "print(sum(list(map(lambda year:year['ethnicity_white_non_asthma'], ldn_utilisation_other_average.values()))) / len(ldn_utilisation_other_average.values()));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
